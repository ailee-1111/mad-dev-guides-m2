= oc / kubectl : 쿠버네티스 클라이언트

* *kubectl*

kubernetes에서 기본적으로 제공 및 사용하는 CLI(CommandLine Interface)입니다. 
Kubernetes API와 상호작용하여 클러스터를 관리하는 데 사용됩니다.
표준 Kubernetes 명령어를 지원하며, 모든 kubernetes기반의 클러스터에서 동작합니다.

* *oc*

OpenShift에서 제공하는 CLI(CommandLine Interface)입니다. 
Kubernetes 기능위에 추가적인 기능(예: 추가 클러스터 관리명령, OpenShift 고유 리소스 관리 등)을 제공합니다.
kubectl 명령어를 기본적으로 포함합니다.


NOTE: 여기서부터 실습에서 사용되는 모든 명령어는 `Lab접속방법`에서 안내되었던 CLI 터미널 창에서 수행됩니다. 

== CLI 터미널 접속

OpenShift 웹콘솔의 오른쪽 상단의 웹터미널 아이콘을 클릭하여 CLI 터미널 창을 엽니다.
그 다음 '시작'버튼을 눌러 터미널을 활성화 합니다.

image::2-1.png[2-1]

image::2-3.png[2-3]

[[talk]]
== 클러스터에 로그인하고, 설정을 확인하세요.

NOTE: 일반적으로 클러스터에서 oc(kubectl) 명령어를 사용하기 위해서는 `oc login` 명령어를 통해 클러스터에 로그인해야 합니다.
이 실습에서는 OpenShift의 웹콘솔에서 제공하는 웹터미널을 사용하기 때문에(이미 웹콘솔 로그인이 되어 있기 때문에) 로그인 단계가 필요없습니다.

[#kubectl-view-config]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl config view
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    server: https://172.30.0.1:443
  name: https://172.30.0.1:443
contexts:
- context:
    cluster: https://172.30.0.1:443
    namespace: openshift-terminal
    user: admin
  name: admin-context
current-context: admin-context
kind: Config
preferences: {}
users:
- name: admin
  user:
    token: REDACTED
----
NOTE: 현재 kubectl 설정 파일의 내용을 출력합니다. 여기에는 클러스터, 사용자 인증 정보, 컨텍스트 등의 정보가 포함됩니다.


[#kubectl-view-config]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc config view
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    server: https://172.30.0.1:443
  name: https://172.30.0.1:443
contexts:
- context:
    cluster: https://172.30.0.1:443
    namespace: openshift-terminal
    user: admin
  name: admin-context
current-context: admin-context
kind: Config
preferences: {}
users:
- name: admin
  user:
    token: REDACTED
----

NOTE: 기본적으로 `oc` 명령어는 `kubectl` 명령을 포함하고 있기 때문에 두 명령어의 결과는 동일합니다.또한 `oc` 명령어는 `kubectl` 에는 포함되어 있지않은 추가 리소스에 대한 명령어도 포함하고 있습니다.앞으로의 실습에는 `oc` 명령어를 사용합니다.



[[view-nodes]]
== 클러스터를 구성하는 Nodes를 확인하세요.

[#kubectl-get-nodes]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get nodes
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                                        STATUS   ROLES                  AGE    VERSION
ip-10-0-27-23.us-east-2.compute.internal    Ready    worker                 2d1h   v1.28.14+502c5ce
ip-10-0-29-131.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce
ip-10-0-35-173.us-east-2.compute.internal   Ready    infra,worker           2d     v1.28.14+502c5ce
ip-10-0-38-201.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce
ip-10-0-38-226.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce
ip-10-0-56-21.us-east-2.compute.internal    Ready    control-plane,master   2d1h   v1.28.14+502c5ce
ip-10-0-63-222.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce
----

[#kubectl-get-nodes]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get nodes --show-labels
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                                        STATUS   ROLES                  AGE    VERSION            LABELS
ip-10-0-27-23.us-east-2.compute.internal    Ready    worker                 2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m6a.8xlarge,beta.kubernetes.io/os=linux,cluster.ocs.openshift.io/openshift-storage=,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-27-23.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m6a.8xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a,topology.rook.io/rack=rack0
ip-10-0-29-131.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m6a.8xlarge,beta.kubernetes.io/os=linux,cluster.ocs.openshift.io/openshift-storage=,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-29-131.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m6a.8xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a,topology.rook.io/rack=rack1
ip-10-0-35-173.us-east-2.compute.internal   Ready    infra,worker           2d     v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-35-173.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/infra=,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-38-201.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-38-201.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-38-226.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-38-226.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-56-21.us-east-2.compute.internal    Ready    control-plane,master   2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-56-21.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-63-222.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m6a.8xlarge,beta.kubernetes.io/os=linux,cluster.ocs.openshift.io/openshift-storage=,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-63-222.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m6a.8xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a,topology.rook.io/rack=rack2[[view-pods]]
----

NOTE: `oc get nodes` : 클러스터 내의 모든 노드를 목록으로 출력합니다.
`oc get nodes --show-labels` : 노드의 정보를 출력하면서 각 노드에 적용된 라벨도 표시합니다.




== View out-of-the-box Pods

Your Kubernetes vendor likely includes many pods out-of-the-box:

[#kubectl-get-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl get pods --all-namespaces
kubectl get pods --all-namespaces --show-labels
kubectl get pods --all-namespaces -o wide
----

[[deploy-app]]
== Deploy Something

Create a Namespace and Deploy something:

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl create namespace mystuff
kubectl config set-context --current --namespace=mystuff

kubectl create deployment myapp --image=quay.io/rhdevelopers/quarkus-demo:v1
----

[[monitor-events]]
== while monitoring Events

[#kubectl-get-events]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch kubectl get events --sort-by=.metadata.creationTimestamp
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
LAST SEEN   TYPE     REASON              OBJECT                        MESSAGE
<unknown>   Normal   Scheduled           pod/myapp-5dcbf46dfc-ghrk4    Successfully assigned mystuff/myapp-5dcbf46dfc-ghrk4 to g
cp-5xldg-w-a-5ptpn.us-central1-a.c.ocp42project.internal
29s         Normal   SuccessfulCreate    replicaset/myapp-5dcbf46dfc   Created pod: myapp-5dcbf46dfc-ghrk4
29s         Normal   ScalingReplicaSet   deployment/myapp              Scaled up replica set myapp-5dcbf46dfc to 1
21s         Normal   Pulling             pod/myapp-5dcbf46dfc-ghrk4    Pulling image "quay.io/burrsutter/quarkus-demo:1.0.0"
15s         Normal   Pulled              pod/myapp-5dcbf46dfc-ghrk4    Successfully pulled image "quay.io/burrsutter/quarkus-dem
o:1.0.0"
15s         Normal   Created             pod/myapp-5dcbf46dfc-ghrk4    Created container quarkus-demo
15s         Normal   Started             pod/myapp-5dcbf46dfc-ghrk4    Started container quarkus-demo
----

[[created-objects]]
== Created Objects

=== Deployments
[#kubectl-get-deployments]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl get deployments
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
myapp   1/1     1            1           95s
----

=== Replicasets
[#kubectl-get-replicasets]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl get replicasets
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME               DESIRED   CURRENT   READY   AGE
myapp-5dcbf46dfc   1         1         1       2m1s
----

=== Pods

[#kubectl-get-podsx]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl get pods --show-labels
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                     READY   STATUS    RESTARTS   AGE     LABELS
myapp-5dcbf46dfc-ghrk4   1/1     Running   0          2m18s   app=myapp,pod-template-hash=5dcbf46dfc
----

=== Logs
[#kubectl-logs]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl logs -l app=myapp
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
2020-03-22 14:41:30,497 INFO  [io.quarkus] (main) Quarkus 0.22.0 started in 0.021s. Listening on: http://0.0.0.0:8080
2020-03-22 14:41:30,497 INFO  [io.quarkus] (main) Installed features: [cdi, resteasy]
----

== Expose a Service
[#kubectl-expose]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl expose deployment myapp --port=8080 --type=LoadBalancer
----

=== while watching Services

:section-k8s: kubectl
include::partial$watching-services.adoc[]

== Talk to the App

:section-k8s: kubectl
:service-exposed: myapp
include::partial$env-curl.adoc[]

== Scale the App

Open three Terminal Windows.

=== Terminal 1
[#watch-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch kubectl get pods
----

=== Terminal 2

:service-exposed: myapp

include::partial$env-curl.adoc[]

Poll the endpoint:

[#poll-endpoint]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
while true
do curl $IP:$PORT
sleep {curl-loop-sleep-time}
done
----

Results of the polling:

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:289
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:290
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:291
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:292
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:293
----

=== Terminal 3

Change replicas:

[#change-replicas]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl scale deployment myapp --replicas=3
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                     READY   STATUS              RESTARTS   AGE
myapp-5dcbf46dfc-6sn2s   0/1     ContainerCreating   0          4s
myapp-5dcbf46dfc-ghrk4   1/1     Running             0          5m32s
myapp-5dcbf46dfc-z6hqw   0/1     ContainerCreating   0          4s
----

Start a rolling update by changing the image:

[#set-image-myboot-v1]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/myboot:v1
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-6sn2s:188
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-z6hqw:169
Aloha from Spring Boot! 0 on myapp-58b97dbd95-vxd87
Aloha from Spring Boot! 1 on myapp-58b97dbd95-vxd87
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-6sn2s:189
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-z6hqw:170
Aloha from Spring Boot! 2 on myapp-58b97dbd95-vxd87
----

[#set-image-myboot-v2]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/myboot:v2
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Bonjour from Spring Boot! 2 on myapp-7d58855c6b-6c8gd
Bonjour from Spring Boot! 3 on myapp-7d58855c6b-6c8gd
Aloha from Spring Boot! 7 on myapp-58b97dbd95-mjlwx
Bonjour from Spring Boot! 4 on myapp-7d58855c6b-6c8gd
Aloha from Spring Boot! 8 on myapp-58b97dbd95-mjlwx
Bonjour from Spring Boot! 5 on myapp-7d58855c6b-6c8gd
----

[#set-image-quarkus-demo]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/quarkus-demo:v1
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Bonjour from Spring Boot! 14 on myapp-7d58855c6b-dw67s
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:3
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:4
Bonjour from Spring Boot! 15 on myapp-7d58855c6b-dw67s
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:5
Bonjour from Spring Boot! 13 on myapp-7d58855c6b-72wp8
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:1
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:2
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:1
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:3
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:2
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:3
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:6
----

=== Clean Up
[#delete-namespace]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl delete namespace mystuff
kubectl config set-context --current --namespace=default
----
